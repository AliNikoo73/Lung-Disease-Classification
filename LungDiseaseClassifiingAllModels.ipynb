{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 # type: ignore\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator  # type: ignore\n",
    "from tensorflow.keras.applications import (  # type: ignore\n",
    "    VGG16,\n",
    "    VGG19,\n",
    "    Xception,\n",
    "    InceptionV3,\n",
    "    MobileNetV2,\n",
    "    DenseNet201,\n",
    "    NASNetLarge,\n",
    "    InceptionResNetV2,\n",
    "    ResNet152V2,\n",
    ")  # Add more models as needed\n",
    "from tensorflow.keras.models import Model  # type: ignore\n",
    "from tensorflow.keras.layers import (  # type: ignore\n",
    "    Input,\n",
    "    Dense,\n",
    "    Flatten,\n",
    "    BatchNormalization,\n",
    "    Dropout,\n",
    "    Conv2D,\n",
    "    GlobalAveragePooling2D,\n",
    ")  # type: ignore\n",
    "from tensorflow.keras.optimizers import SGD # type: ignore\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set a fixed seed for reproducibility\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "# Suppress warnings for clean output\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "# Print GPU information\n",
    "print(\"\\n\" + \"==\" * 50)\n",
    "print(\"üöÄ Num GPUs Available: \", len(tf.config.list_physical_devices(\"GPU\")))\n",
    "if gpus := tf.config.experimental.list_physical_devices(\"GPU\"):\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(\"‚úÖ GPU memory growth enabled.\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"‚ö†Ô∏è {e}\")\n",
    "print(\"==\" * 50 + \"\\n\")\n",
    "\n",
    "# Define the path to your dataset\n",
    "data_path = \"images/lung disease/train\"\n",
    "test_data_path = \"images/lung disease/test\"\n",
    "classes = os.listdir(data_path)\n",
    "\n",
    "# Specify parameters\n",
    "img_size = (224, 224)  # Updated to match the expected input shape of pre-trained models\n",
    "batch_size = 32\n",
    "initial_epochs = 1  # Initial training with frozen base model layers\n",
    "NNeuron = 256\n",
    "DO_factor = 0.5\n",
    "version = \"1.7\"  # Code version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use simple ImageDataGenerator\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2,\n",
    ")\n",
    "\n",
    "# Create generators for training and validation sets\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    data_path,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    color_mode=\"rgb\",\n",
    "    class_mode=\"categorical\",\n",
    "    subset=\"training\",\n",
    ")\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    data_path,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    color_mode=\"rgb\",\n",
    "    class_mode=\"categorical\",\n",
    "    subset=\"validation\",\n",
    ")\n",
    "\n",
    "# Create a generator for the test set\n",
    "test_generator = datagen.flow_from_directory(\n",
    "    test_data_path,\n",
    "    target_size=img_size,\n",
    "    batch_size=1,\n",
    "    color_mode=\"rgb\",\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "# Mapping between class indices and class labels\n",
    "class_indices = test_generator.class_indices\n",
    "index_to_class = {v: k for k, v in class_indices.items()}\n",
    "\n",
    "# List of base models to use\n",
    "base_models = {\n",
    "    \"ResNet152V2\": ResNet152V2,\n",
    "    \"DenseNet201\": DenseNet201,\n",
    "    \"VGG16\": VGG16,\n",
    "    \"VGG19\": VGG19,\n",
    "    \"Xception\": Xception,\n",
    "    \"InceptionV3\": InceptionV3,\n",
    "    \"InceptionResNetV2\": InceptionResNetV2,\n",
    "    \"MobileNetV2\": MobileNetV2,\n",
    "    \"NASNetLarge\": NASNetLarge,\n",
    "    # Add more models if needed\n",
    "}\n",
    "\n",
    "# Dictionary to store results for bar chart\n",
    "model_metrics = {\n",
    "    \"Model\": [],\n",
    "    \"Final Train Accuracy (%)\": [],\n",
    "    \"Final Train Loss\": [],\n",
    "    \"Final Val Accuracy (%)\": [],\n",
    "    \"Final Val Loss\": [],\n",
    "    \"Final Test Accuracy (%)\": [],\n",
    "    \"Final Test Loss\": [],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create and compile a model with the given base model\n",
    "def create_fine_tune_model(base_model_name, NNeuron, DO_factor):\n",
    "    base_model_class = base_models[base_model_name]\n",
    "    base_model = base_model_class(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "    # Add new layers on top of the base model\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)  # Global average pooling\n",
    "    x = Dense(NNeuron, activation=\"relu\")(x)  # Fully connected layer\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(DO_factor)(x)\n",
    "    predictions = Dense(train_generator.num_classes, activation=\"softmax\")(x)  # Output layer\n",
    "    \n",
    "    layers_conf_list = [\n",
    "        \"GlobalAvgPooling\",\n",
    "        f\"Dense_{NNeuron}_relu\",\n",
    "        \"BatchNorm\",\n",
    "        f\"Dropout_{DO_factor}\",\n",
    "    ]\n",
    "\n",
    "    # Create the final model\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    # Freeze the base model layers initially\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    return model, base_model, layers_conf_list\n",
    "\n",
    "# Function to fine-tune the model\n",
    "def fine_tune_model(model, base_model, unfreeze_from):\n",
    "    # Unfreeze the top layers starting from 'unfreeze_from'\n",
    "    for layer in base_model.layers[:unfreeze_from]:\n",
    "        layer.trainable = False\n",
    "    for layer in base_model.layers[unfreeze_from:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # Recompile the model with a lower learning rate for fine-tuning\n",
    "    model.compile(optimizer=SGD(learning_rate=0.0001, momentum=0.9), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "# Function to save model results\n",
    "def save_results(\n",
    "    trial_name, history, val_accuracy, val_loss, test_accuracy, test_loss, base_path\n",
    "):\n",
    "    results_csv = os.path.join(base_path, f\"{trial_name}_model_results.csv\")\n",
    "    with open(results_csv, \"w\", newline=\"\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(\n",
    "            [\n",
    "                \"Epoch\",\n",
    "                \"Train Accuracy (%)\",\n",
    "                \"Train Loss\",\n",
    "                \"Val Accuracy (%)\",\n",
    "                \"Val Loss\",\n",
    "                \"Test Accuracy (%)\",\n",
    "                \"Test Loss\",\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Iterate over each epoch to record metrics\n",
    "        for epoch in range(len(history.history[\"accuracy\"])):\n",
    "            train_acc = round(history.history[\"accuracy\"][epoch] * 100, 2)\n",
    "            train_loss = round(history.history[\"loss\"][epoch], 4)\n",
    "            val_acc = round(history.history[\"val_accuracy\"][epoch] * 100, 2)\n",
    "            val_loss = round(history.history[\"val_loss\"][epoch], 4)\n",
    "\n",
    "            # Only include test accuracy and loss for the last epoch\n",
    "            if epoch == len(history.history[\"accuracy\"]) - 1:\n",
    "                test_acc = (\n",
    "                    round(float(test_accuracy) * 100, 2) if test_accuracy != \"\" else \"\"\n",
    "                )\n",
    "                test_loss = round(float(test_loss), 4) if test_loss != \"\" else \"\"\n",
    "            else:\n",
    "                test_acc, test_loss = \"\", \"\"\n",
    "\n",
    "            writer.writerow(\n",
    "                [\n",
    "                    epoch + 1,\n",
    "                    train_acc,\n",
    "                    train_loss,\n",
    "                    val_acc,\n",
    "                    val_loss,\n",
    "                    test_acc,\n",
    "                    test_loss,\n",
    "                ]\n",
    "            )\n",
    "\n",
    "# Function to plot and save accuracy and loss\n",
    "def plot_metrics(history, trial_name, base_path):\n",
    "    epochs = range(1, len(history.history[\"accuracy\"]) + 1)  # Generate epoch numbers\n",
    "\n",
    "    # Convert accuracy to percentage\n",
    "    train_accuracy = [round(acc * 100, 2) for acc in history.history[\"accuracy\"]]\n",
    "    val_accuracy = [round(acc * 100, 2) for acc in history.history[\"val_accuracy\"]]\n",
    "\n",
    "    # Plot accuracy\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, train_accuracy, label=\"Train Accuracy\")\n",
    "    plt.plot(epochs, val_accuracy, label=\"Validation Accuracy\")\n",
    "    plt.title(f\"{trial_name}_Model Accuracy\")\n",
    "    plt.ylabel(\"Accuracy (%)\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.xticks(epochs)  # Set x-axis ticks to integers\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.savefig(os.path.join(base_path, f\"{trial_name}_accuracy.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    # Plot loss\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, history.history[\"loss\"], label=\"Train Loss\")\n",
    "    plt.plot(epochs, history.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "    plt.title(f\"{trial_name}_Model Loss\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.xticks(epochs)  # Set x-axis ticks to integers\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.savefig(os.path.join(base_path, f\"{trial_name}_loss.png\"))\n",
    "    plt.close()\n",
    "\n",
    "# Function to plot and save predictions for random test images\n",
    "def plot_predictions(trial_name, model, base_path, test_generator, index_to_class):\n",
    "    # Select 20 random indices from test data\n",
    "    random_indices = random.sample(range(len(test_generator.filenames)), 20)\n",
    "    selected_images, selected_labels = [], []\n",
    "\n",
    "    for idx in random_indices:\n",
    "        img, label = test_generator[idx]\n",
    "        selected_images.append(img[0])\n",
    "        selected_labels.append(label[0])\n",
    "\n",
    "    # Make predictions on selected images\n",
    "    predictions = model.predict(np.array(selected_images))\n",
    "\n",
    "    # Plot the images with their true and predicted labels\n",
    "    fig, axes = plt.subplots(4, 5, figsize=(15, 12))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, ax in enumerate(axes):\n",
    "        ax.imshow(selected_images[i].squeeze(), cmap=\"gray\")\n",
    "        true_label = index_to_class[np.argmax(selected_labels[i])]\n",
    "        predicted_label = index_to_class[np.argmax(predictions[i])]\n",
    "        ax.set_title(f\"True: {true_label}\\nPred: {predicted_label}\")\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(base_path, f\"{trial_name}_random_predictions.png\"))\n",
    "    plt.close()\n",
    "\n",
    "# Grad-CAM Function\n",
    "def get_gradcam_heatmap(model, img_array, last_conv_layer_name, pred_index=None):\n",
    "    grad_model = Model(\n",
    "        inputs=[model.inputs],\n",
    "        outputs=[model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        last_conv_layer_output, preds = grad_model(img_array)\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(preds[0])\n",
    "        class_channel = preds[:, pred_index]\n",
    "\n",
    "    # Get the gradients of the target class with respect to the output feature map\n",
    "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
    "    \n",
    "    # Pool the gradients across the feature map\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "    # Weigh the output feature map by the pooled gradients\n",
    "    last_conv_layer_output = last_conv_layer_output[0]\n",
    "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "\n",
    "    # Normalize the heatmap between 0 and 1 for visualization\n",
    "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "    return heatmap.numpy()\n",
    "\n",
    "# Function to overlay the heatmap on the original image\n",
    "def overlay_gradcam_heatmap(img, heatmap, alpha=0.4):\n",
    "    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "    \n",
    "\n",
    "    return cv2.addWeighted(img, 1 - alpha, heatmap, alpha, 0)\n",
    "\n",
    "# Function to display and save Grad-CAM for a single image\n",
    "def display_gradcam(img_path, model, last_conv_layer_name, base_path, alpha=0.4):\n",
    "    # Load and preprocess the image\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array = img_array / 255.0  # Normalize image\n",
    "    \n",
    "    # Generate the Grad-CAM heatmap\n",
    "    heatmap = get_gradcam_heatmap(model, img_array, last_conv_layer_name)\n",
    "    \n",
    "    # Read the original image with OpenCV\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, (224, 224))\n",
    "\n",
    "    # Overlay the heatmap on the original image\n",
    "    superimposed_img = overlay_gradcam_heatmap(img, heatmap, alpha=alpha)\n",
    "\n",
    "    # Display original and superimposed images (optional)\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    ax[0].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    ax[0].set_title('Original Image')\n",
    "    ax[0].axis('off')\n",
    "\n",
    "    ax[1].imshow(cv2.cvtColor(superimposed_img, cv2.COLOR_BGR2RGB))\n",
    "    ax[1].set_title('Grad-CAM')\n",
    "    ax[1].axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    # Save the superimposed Grad-CAM image\n",
    "    gradcam_filename = os.path.join(base_path, f\"gradcam_{os.path.basename(img_path)}\")\n",
    "    cv2.imwrite(gradcam_filename, superimposed_img)\n",
    "    print(f\"‚úÖ Grad-CAM saved to: {gradcam_filename}\")\n",
    "\n",
    "# Function to generate Grad-CAM for random test images\n",
    "def gradcam_for_test_images(model, test_generator, last_conv_layer_name, num_images=5):\n",
    "    random_indices = random.sample(range(len(test_generator.filenames)), num_images)\n",
    "    for idx in random_indices:\n",
    "        img_path = os.path.join(test_generator.directory, test_generator.filenames[idx])\n",
    "        print(f\"Generating Grad-CAM for: {img_path}\")\n",
    "        display_gradcam(img_path, model, last_conv_layer_name, base_path)\n",
    "\n",
    "# Function to find the last Conv2D layer in the model\n",
    "def find_last_conv_layer(model):\n",
    "    last_conv_layer_name = next(\n",
    "        (\n",
    "            layer.name\n",
    "            for layer in reversed(model.layers)\n",
    "            if isinstance(layer, tf.keras.layers.Conv2D)\n",
    "        ),\n",
    "        None,\n",
    "    )\n",
    "    if last_conv_layer_name:\n",
    "        print(f\"üîç Last Conv2D layer in {model.name}: {last_conv_layer_name}\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è No Conv2D layer found in {model.name}\")\n",
    "    return last_conv_layer_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform trials with each base model\n",
    "for base_model_name in base_models.keys():\n",
    "    trial_name = f\"trial_{base_model_name}\"\n",
    "    print(\"\\n\" + \"==\" * 50)\n",
    "    print(f\"üöÄ Starting {trial_name} with base model: {base_model_name}\")\n",
    "    print(\"==\" * 50 + \"\\n\")\n",
    "\n",
    "    # Step 1: Train the model with frozen base model layers\n",
    "    model, base_model, layers_conf_list = create_fine_tune_model(base_model_name, NNeuron, DO_factor)\n",
    "    # model.summary()\n",
    "    # Create a directory for storing results for the current model\n",
    "    layers_conf_str = '_'.join(layers_conf_list)  # Convert layers config list to a string\n",
    "    base_path = os.path.join(f'Projects/Lung disease/All models/results/CNFG {layers_conf_str}_EPCH {initial_epochs}_VRSN {version}', f\"BSMD {base_model_name}\")\n",
    "    os.makedirs(base_path, exist_ok=True)\n",
    "\n",
    "    last_conv_layer_name = find_last_conv_layer(base_model)\n",
    "\n",
    "    if last_conv_layer_name is None:\n",
    "        print(f\"‚ö†Ô∏è Skipping Grad-CAM for {base_model_name} due to no Conv2D layer.\")\n",
    "        continue  # Skip Grad-CAM if no Conv2D layer is found\n",
    "\n",
    "    history = model.fit(train_generator, epochs=initial_epochs, validation_data=validation_generator)\n",
    "\n",
    "    # Evaluate the model on validation data\n",
    "    val_loss, val_accuracy = model.evaluate(validation_generator)\n",
    "\n",
    "    # Evaluate the model on test data\n",
    "    test_loss, test_accuracy = model.evaluate(test_generator)\n",
    "\n",
    "    # Save results and plots\n",
    "    save_results(trial_name, history, val_accuracy, val_loss, test_accuracy, test_loss, base_path)\n",
    "    plot_metrics(history, trial_name, base_path)\n",
    "\n",
    "    # Save the fine-tuned model\n",
    "    model.save(os.path.join(base_path, f\"{trial_name}_model.h5\"))\n",
    "\n",
    "    # Plot predictions for 20 random images\n",
    "    plot_predictions(trial_name, model, base_path, test_generator, index_to_class)\n",
    "\n",
    "    # Generate Grad-CAM for 5 random test images\n",
    "    gradcam_for_test_images(model, test_generator, last_conv_layer_name, num_images=5)\n",
    "\n",
    "    # Store final metrics for bar chart\n",
    "    model_metrics[\"Model\"].append(base_model_name)\n",
    "    model_metrics[\"Final Train Accuracy (%)\"].append(round(history.history[\"accuracy\"][-1] * 100, 2))\n",
    "    model_metrics[\"Final Train Loss\"].append(round(history.history[\"loss\"][-1], 4))\n",
    "    model_metrics[\"Final Val Accuracy (%)\"].append(round(history.history[\"val_accuracy\"][-1] * 100, 2))\n",
    "    model_metrics[\"Final Val Loss\"].append(round(history.history[\"val_loss\"][-1], 4))\n",
    "    model_metrics[\"Final Test Accuracy (%)\"].append(round(test_accuracy * 100, 2))\n",
    "    model_metrics[\"Final Test Loss\"].append(round(test_loss, 4))\n",
    "\n",
    "    print(f\"‚úÖ {trial_name} completed and results saved.\")\n",
    "\n",
    "    # Clear session to prevent memory buildup\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "print(\"\\n\" + \"==\" * 50)\n",
    "print(\"üéâ All model trials completed!\")\n",
    "print(\"==\" * 50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot bar chart comparing accuracy and loss of each model\n",
    "fig, ax = plt.subplots(1, 2, figsize=(18, 8))\n",
    "\n",
    "# Colors for the bars\n",
    "train_color = \"lightblue\"\n",
    "val_color = \"lightgreen\"\n",
    "test_color = \"salmon\"\n",
    "\n",
    "# Plot accuracy bar chart\n",
    "width = 0.25  # Width of each bar\n",
    "\n",
    "r1 = np.arange(len(model_metrics[\"Model\"]))  # X positions for train bars\n",
    "r2 = [x + width for x in r1]  # X positions for validation bars\n",
    "r3 = [x + 2 * width for x in r1]  # X positions for test bars\n",
    "\n",
    "ax[0].bar(\n",
    "    r1,\n",
    "    model_metrics[\"Final Train Accuracy (%)\"],\n",
    "    color=train_color,\n",
    "    width=width,\n",
    "    label=\"Train Accuracy\",\n",
    ")\n",
    "ax[0].bar(\n",
    "    r2,\n",
    "    model_metrics[\"Final Val Accuracy (%)\"],\n",
    "    color=val_color,\n",
    "    width=width,\n",
    "    label=\"Validation Accuracy\",\n",
    ")\n",
    "ax[0].bar(\n",
    "    r3,\n",
    "    model_metrics[\"Final Test Accuracy (%)\"],\n",
    "    color=test_color,\n",
    "    width=width,\n",
    "    label=\"Test Accuracy\",\n",
    ")\n",
    "\n",
    "# Display the accuracy values on top of the bars\n",
    "for i in range(len(model_metrics[\"Model\"])):\n",
    "    ax[0].text(\n",
    "        r1[i],\n",
    "        model_metrics[\"Final Train Accuracy (%)\"][i] + 0.5,\n",
    "        f\"{model_metrics['Final Train Accuracy (%)'][i]:.2f}%\",\n",
    "        ha=\"center\",\n",
    "        color=\"black\",\n",
    "    )\n",
    "    ax[0].text(\n",
    "        r2[i],\n",
    "        model_metrics[\"Final Val Accuracy (%)\"][i] + 0.5,\n",
    "        f\"{model_metrics['Final Val Accuracy (%)'][i]:.2f}%\",\n",
    "        ha=\"center\",\n",
    "        color=\"black\",\n",
    "    )\n",
    "    ax[0].text(\n",
    "        r3[i],\n",
    "        model_metrics[\"Final Test Accuracy (%)\"][i] + 0.5,\n",
    "        f\"{model_metrics['Final Test Accuracy (%)'][i]:.2f}%\",\n",
    "        ha=\"center\",\n",
    "        color=\"black\",\n",
    "    )\n",
    "\n",
    "# Labeling and title for accuracy chart\n",
    "ax[0].set_title(\"Final Accuracy of Models\", fontsize=14)\n",
    "ax[0].set_ylabel(\"Accuracy (%)\")\n",
    "ax[0].set_xticks([r + width for r in range(len(model_metrics[\"Model\"]))])\n",
    "ax[0].set_xticklabels(model_metrics[\"Model\"])\n",
    "# Place the legend outside the accuracy chart\n",
    "ax[0].legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "ax[0].tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "# Plot loss bar chart\n",
    "ax[1].bar(\n",
    "    r1,\n",
    "    model_metrics[\"Final Train Loss\"],\n",
    "    color=train_color,\n",
    "    width=width,\n",
    "    label=\"Train Loss\",\n",
    ")\n",
    "ax[1].bar(\n",
    "    r2,\n",
    "    model_metrics[\"Final Val Loss\"],\n",
    "    color=val_color,\n",
    "    width=width,\n",
    "    label=\"Validation Loss\",\n",
    ")\n",
    "ax[1].bar(\n",
    "    r3,\n",
    "    model_metrics[\"Final Test Loss\"],\n",
    "    color=test_color,\n",
    "    width=width,\n",
    "    label=\"Test Loss\",\n",
    ")\n",
    "\n",
    "# Display the loss values on top of the bars\n",
    "for i in range(len(model_metrics[\"Model\"])):\n",
    "    ax[1].text(\n",
    "        r1[i],\n",
    "        model_metrics[\"Final Train Loss\"][i] + 0.01,\n",
    "        f\"{model_metrics['Final Train Loss'][i]:.4f}\",\n",
    "        ha=\"center\",\n",
    "        color=\"black\",\n",
    "    )\n",
    "    ax[1].text(\n",
    "        r2[i],\n",
    "        model_metrics[\"Final Val Loss\"][i] + 0.01,\n",
    "        f\"{model_metrics['Final Val Loss'][i]:.4f}\",\n",
    "        ha=\"center\",\n",
    "        color=\"black\",\n",
    "    )\n",
    "    ax[1].text(\n",
    "        r3[i],\n",
    "        model_metrics[\"Final Test Loss\"][i] + 0.01,\n",
    "        f\"{model_metrics['Final Test Loss'][i]:.4f}\",\n",
    "        ha=\"center\",\n",
    "        color=\"black\",\n",
    "    )\n",
    "\n",
    "# Labeling and title for loss chart\n",
    "ax[1].set_title(\"Final Loss of Models\", fontsize=14)\n",
    "ax[1].set_ylabel(\"Loss\")\n",
    "ax[1].set_xticks([r + width for r in range(len(model_metrics[\"Model\"]))])\n",
    "ax[1].set_xticklabels(model_metrics[\"Model\"])\n",
    "# Place the legend outside the loss chart\n",
    "ax[1].legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "ax[1].tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    f'Projects/Lung disease/All models/results/CNFG {layers_conf_str}_EPCH {initial_epochs}_VRSN {version}/comparison_bar_chart_with_test.png'\n",
    ")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
